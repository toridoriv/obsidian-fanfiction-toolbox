[
  {
    "provider": "GoogleAiProvider",
    "id": "models/gemini-1.0-pro",
    "name": "Gemini 1.0 Pro",
    "description": "The best model for scaling across a wide range of tasks",
    "version": "001",
    "inputTokenLimit": 30720,
    "outputTokenLimit": 2048,
    "supportedOperations": ["generateContent", "countTokens"],
    "temperature": 0.9,
    "requestsPerDay": -1,
    "availableRequests": -1,
    "timestamp": "2024-05-12T21:23:46.750Z",
    "apiVersion": "v1",
    "uniqueId": "google:v1:gemini-1.0-pro:001"
  },
  {
    "provider": "GoogleAiProvider",
    "id": "models/gemini-1.0-pro-001",
    "name": "Gemini 1.0 Pro 001 (Tuning)",
    "description": "The best model for scaling across a wide range of tasks. This is a stable model that supports tuning.",
    "version": "001",
    "inputTokenLimit": 30720,
    "outputTokenLimit": 2048,
    "supportedOperations": ["generateContent", "countTokens", "createTunedModel"],
    "temperature": 0.9,
    "requestsPerDay": -1,
    "availableRequests": -1,
    "timestamp": "2024-05-12T21:23:46.751Z",
    "apiVersion": "v1",
    "uniqueId": "google:v1:gemini-1.0-pro-001"
  },
  {
    "provider": "GoogleAiProvider",
    "id": "models/gemini-1.0-pro-latest",
    "name": "Gemini 1.0 Pro Latest",
    "description": "The best model for scaling across a wide range of tasks. This is the latest model.",
    "version": "001",
    "inputTokenLimit": 30720,
    "outputTokenLimit": 2048,
    "supportedOperations": ["generateContent", "countTokens"],
    "temperature": 0.9,
    "requestsPerDay": -1,
    "availableRequests": -1,
    "timestamp": "2024-05-12T21:23:46.752Z",
    "apiVersion": "v1",
    "uniqueId": "google:v1:gemini-1.0-pro-latest:001"
  },
  {
    "provider": "GoogleAiProvider",
    "id": "models/gemini-1.0-pro-vision-latest",
    "name": "Gemini 1.0 Pro Vision",
    "description": "The best image understanding model to handle a broad range of applications",
    "version": "001",
    "inputTokenLimit": 12288,
    "outputTokenLimit": 4096,
    "supportedOperations": ["generateContent", "countTokens"],
    "temperature": 0.4,
    "requestsPerDay": -1,
    "availableRequests": -1,
    "timestamp": "2024-05-12T21:23:46.752Z",
    "apiVersion": "v1",
    "uniqueId": "google:v1:gemini-1.0-pro-vision-latest:001"
  },
  {
    "provider": "GoogleAiProvider",
    "id": "models/gemini-pro",
    "name": "Gemini 1.0 Pro",
    "description": "The best model for scaling across a wide range of tasks",
    "version": "001",
    "inputTokenLimit": 30720,
    "outputTokenLimit": 2048,
    "supportedOperations": ["generateContent", "countTokens"],
    "temperature": 0.9,
    "requestsPerDay": -1,
    "availableRequests": -1,
    "timestamp": "2024-05-12T21:23:46.752Z",
    "apiVersion": "v1",
    "uniqueId": "google:v1:gemini-pro:001"
  },
  {
    "provider": "GoogleAiProvider",
    "id": "models/gemini-pro-vision",
    "name": "Gemini 1.0 Pro Vision",
    "description": "The best image understanding model to handle a broad range of applications",
    "version": "001",
    "inputTokenLimit": 12288,
    "outputTokenLimit": 4096,
    "supportedOperations": ["generateContent", "countTokens"],
    "temperature": 0.4,
    "requestsPerDay": -1,
    "availableRequests": -1,
    "timestamp": "2024-05-12T21:23:46.752Z",
    "apiVersion": "v1",
    "uniqueId": "google:v1:gemini-pro-vision:001"
  },
  {
    "provider": "GoogleAiProvider",
    "id": "models/embedding-001",
    "name": "Embedding 001",
    "description": "Obtain a distributed representation of a text.",
    "version": "001",
    "inputTokenLimit": 2048,
    "outputTokenLimit": 1,
    "supportedOperations": ["embedContent"],
    "temperature": 0.8,
    "requestsPerDay": -1,
    "availableRequests": -1,
    "timestamp": "2024-05-12T21:23:46.752Z",
    "apiVersion": "v1",
    "uniqueId": "google:v1:embedding-001"
  },
  {
    "provider": "GoogleAiProvider",
    "id": "models/text-embedding-004",
    "name": "Text Embedding 004",
    "description": "Obtain a distributed representation of a text.",
    "version": "004",
    "inputTokenLimit": 2048,
    "outputTokenLimit": 1,
    "supportedOperations": ["embedContent"],
    "temperature": 0.8,
    "requestsPerDay": -1,
    "availableRequests": -1,
    "timestamp": "2024-05-12T21:23:46.753Z",
    "apiVersion": "v1",
    "uniqueId": "google:v1:text-embedding-004"
  },
  {
    "provider": "GoogleAiProvider",
    "id": "models/chat-bison-001",
    "name": "PaLM 2 Chat (Legacy)",
    "description": "A legacy text-only model optimized for chat conversations",
    "version": "001",
    "inputTokenLimit": 4096,
    "outputTokenLimit": 1024,
    "supportedOperations": ["generateMessage", "countMessageTokens"],
    "temperature": 0.25,
    "requestsPerDay": -1,
    "availableRequests": -1,
    "timestamp": "2024-05-12T21:23:46.891Z",
    "apiVersion": "v1beta",
    "uniqueId": "google:v1beta:chat-bison-001"
  },
  {
    "provider": "GoogleAiProvider",
    "id": "models/text-bison-001",
    "name": "PaLM 2 (Legacy)",
    "description": "A legacy model that understands text and generates text as an output",
    "version": "001",
    "inputTokenLimit": 8196,
    "outputTokenLimit": 1024,
    "supportedOperations": ["generateText", "countTextTokens", "createTunedTextModel"],
    "temperature": 0.7,
    "requestsPerDay": -1,
    "availableRequests": -1,
    "timestamp": "2024-05-12T21:23:46.891Z",
    "apiVersion": "v1beta",
    "uniqueId": "google:v1beta:text-bison-001"
  },
  {
    "provider": "GoogleAiProvider",
    "id": "models/embedding-gecko-001",
    "name": "Embedding Gecko",
    "description": "Obtain a distributed representation of a text.",
    "version": "001",
    "inputTokenLimit": 1024,
    "outputTokenLimit": 1,
    "supportedOperations": ["embedText", "countTextTokens"],
    "temperature": 0.8,
    "requestsPerDay": -1,
    "availableRequests": -1,
    "timestamp": "2024-05-12T21:23:46.891Z",
    "apiVersion": "v1beta",
    "uniqueId": "google:v1beta:embedding-gecko-001"
  },
  {
    "provider": "GoogleAiProvider",
    "id": "models/gemini-1.0-pro",
    "name": "Gemini 1.0 Pro",
    "description": "The best model for scaling across a wide range of tasks",
    "version": "001",
    "inputTokenLimit": 30720,
    "outputTokenLimit": 2048,
    "supportedOperations": ["generateContent", "countTokens"],
    "temperature": 0.9,
    "requestsPerDay": -1,
    "availableRequests": -1,
    "timestamp": "2024-05-12T21:23:46.891Z",
    "apiVersion": "v1beta",
    "uniqueId": "google:v1beta:gemini-1.0-pro:001"
  },
  {
    "provider": "GoogleAiProvider",
    "id": "models/gemini-1.0-pro-001",
    "name": "Gemini 1.0 Pro 001 (Tuning)",
    "description": "The best model for scaling across a wide range of tasks. This is a stable model that supports tuning.",
    "version": "001",
    "inputTokenLimit": 30720,
    "outputTokenLimit": 2048,
    "supportedOperations": ["generateContent", "countTokens", "createTunedModel"],
    "temperature": 0.9,
    "requestsPerDay": -1,
    "availableRequests": -1,
    "timestamp": "2024-05-12T21:23:46.892Z",
    "apiVersion": "v1beta",
    "uniqueId": "google:v1beta:gemini-1.0-pro-001"
  },
  {
    "provider": "GoogleAiProvider",
    "id": "models/gemini-1.0-pro-latest",
    "name": "Gemini 1.0 Pro Latest",
    "description": "The best model for scaling across a wide range of tasks. This is the latest model.",
    "version": "001",
    "inputTokenLimit": 30720,
    "outputTokenLimit": 2048,
    "supportedOperations": ["generateContent", "countTokens"],
    "temperature": 0.9,
    "requestsPerDay": -1,
    "availableRequests": -1,
    "timestamp": "2024-05-12T21:23:46.892Z",
    "apiVersion": "v1beta",
    "uniqueId": "google:v1beta:gemini-1.0-pro-latest:001"
  },
  {
    "provider": "GoogleAiProvider",
    "id": "models/gemini-1.0-pro-vision-latest",
    "name": "Gemini 1.0 Pro Vision",
    "description": "The best image understanding model to handle a broad range of applications",
    "version": "001",
    "inputTokenLimit": 12288,
    "outputTokenLimit": 4096,
    "supportedOperations": ["generateContent", "countTokens"],
    "temperature": 0.4,
    "requestsPerDay": -1,
    "availableRequests": -1,
    "timestamp": "2024-05-12T21:23:46.892Z",
    "apiVersion": "v1beta",
    "uniqueId": "google:v1beta:gemini-1.0-pro-vision-latest:001"
  },
  {
    "provider": "GoogleAiProvider",
    "id": "models/gemini-1.5-pro-latest",
    "name": "Gemini 1.5 Pro",
    "description": "Mid-size multimodal model that supports up to 1 million tokens",
    "version": "001",
    "inputTokenLimit": 1048576,
    "outputTokenLimit": 8192,
    "supportedOperations": ["generateContent", "countTokens"],
    "temperature": 1,
    "requestsPerDay": -1,
    "availableRequests": -1,
    "timestamp": "2024-05-12T21:23:46.892Z",
    "apiVersion": "v1beta",
    "uniqueId": "google:v1beta:gemini-1.5-pro-latest:001"
  },
  {
    "provider": "GoogleAiProvider",
    "id": "models/gemini-pro",
    "name": "Gemini 1.0 Pro",
    "description": "The best model for scaling across a wide range of tasks",
    "version": "001",
    "inputTokenLimit": 30720,
    "outputTokenLimit": 2048,
    "supportedOperations": ["generateContent", "countTokens"],
    "temperature": 0.9,
    "requestsPerDay": -1,
    "availableRequests": -1,
    "timestamp": "2024-05-12T21:23:46.892Z",
    "apiVersion": "v1beta",
    "uniqueId": "google:v1beta:gemini-pro:001"
  },
  {
    "provider": "GoogleAiProvider",
    "id": "models/gemini-pro-vision",
    "name": "Gemini 1.0 Pro Vision",
    "description": "The best image understanding model to handle a broad range of applications",
    "version": "001",
    "inputTokenLimit": 12288,
    "outputTokenLimit": 4096,
    "supportedOperations": ["generateContent", "countTokens"],
    "temperature": 0.4,
    "requestsPerDay": -1,
    "availableRequests": -1,
    "timestamp": "2024-05-12T21:23:46.892Z",
    "apiVersion": "v1beta",
    "uniqueId": "google:v1beta:gemini-pro-vision:001"
  },
  {
    "provider": "GoogleAiProvider",
    "id": "models/embedding-001",
    "name": "Embedding 001",
    "description": "Obtain a distributed representation of a text.",
    "version": "001",
    "inputTokenLimit": 2048,
    "outputTokenLimit": 1,
    "supportedOperations": ["embedContent"],
    "temperature": 0.8,
    "requestsPerDay": -1,
    "availableRequests": -1,
    "timestamp": "2024-05-12T21:23:46.893Z",
    "apiVersion": "v1beta",
    "uniqueId": "google:v1beta:embedding-001"
  },
  {
    "provider": "GoogleAiProvider",
    "id": "models/text-embedding-004",
    "name": "Text Embedding 004",
    "description": "Obtain a distributed representation of a text.",
    "version": "004",
    "inputTokenLimit": 2048,
    "outputTokenLimit": 1,
    "supportedOperations": ["embedContent"],
    "temperature": 0.8,
    "requestsPerDay": -1,
    "availableRequests": -1,
    "timestamp": "2024-05-12T21:23:46.893Z",
    "apiVersion": "v1beta",
    "uniqueId": "google:v1beta:text-embedding-004"
  },
  {
    "provider": "GoogleAiProvider",
    "id": "models/aqa",
    "name": "Attributed Question Answering",
    "description": "Model trained to return answers to questions that are grounded in provided sources, along with estimating answerable probability.",
    "version": "001",
    "inputTokenLimit": 7168,
    "outputTokenLimit": 1024,
    "supportedOperations": ["generateAnswer"],
    "temperature": 0.2,
    "requestsPerDay": -1,
    "availableRequests": -1,
    "timestamp": "2024-05-12T21:23:46.893Z",
    "apiVersion": "v1beta",
    "uniqueId": "google:v1beta:aqa:001"
  }
]
